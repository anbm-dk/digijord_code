cov_names = cov_DC_names,  # Character vector, covariate names,
data = trdat_DC, # data frame, input data
bounds_bayes = bounds_DC, # named list with bounds for bayesian opt.
bounds_pred = c(0.5, 5.5), # numeric, length 2, bounds for predicted values
cores = 19, # number cores for parallelization
trgrid = tgrid, # data frame with tuning parameters to be tested in basic model
folds = folds_DC, # list with indices, folds for cross validation
sumfun = WeightedSummary_DC, # summary function for accuracy assessment
metric = "MAEw", # character, length 1, name of evaluation metric
max_metric = FALSE, # logical, should the evaluation metric be maximized
weights = trdat_DC$w, # numeric, weights for model training and evaluation
trees_per_round = 3, # numeric, length 1, number of trees that xgboost should train in each round
obj_xgb = "reg:pseudohubererror", # character, length 1, objective function for xgboost
colsample_bylevel_basic = 0.75, # numeric, colsample_bylevel for basic model
cov_keep = NULL, # Character vector, covariates that should always be present
final_round_mult = 1,  # Multiplier for the number of rounds in the final model
seed = 321  # Random seed for model training
)
?bayesOpt
# TO DO:
# First: Predict soil drainage classes:
# Import soil drainage classes (get correct coordinates first)
# Extract covariates
# Include texture predictions as covariates
# Rearrange tiles for texture predictions to fit covariate structure
# Make summary function with weighted MAE for accuracy
# Calculate weights
# Train xgboost regression model,
# Analyse results
# Make map for test area
# Make national map
# Secondly: Predict artificially drained areas
# Import and merge data:
# - 7 km grid (original coordinates) (or new LR pts?)
# - data from orbicon
# - data from Landskontoret for Planteavl
# Aggregate relevant covariates at field scale (including new texture maps and
# soil drainage classes)
# Split into tiles
# Extract covariates
# Make summary function for weighted accuracy (or weighted AUC?)
# Calculate weights (sum of weights should be equal for drained and undrained
# points)
# Train xgboost classification model
# Analyse results
# Make map for test area
# Make national map
# 1: Start up
library(terra)
library(magrittr)
library(tools)
library(dplyr)
library(caret)
library(tibble)
library(tidyr)
library(sf)
library(exactextractr)
library(party)
library(rpart)
library(doParallel)
library(spatstat) # weights
library(RODBC)
dir_code <- getwd()
root <- dirname(dir_code)
dir_dat <- paste0(root, "/digijord_data/")
testn <- 13
mycrs <- "EPSG:25832"
fraction_names_underscore <- c(
"Clay", "Silt", "Fine_sand", "Coarse_sand", "SOC", "CaCO3"
)
# Results folder
dir_results <- dir_dat %>%
paste0(., "/results_test_", testn, "/") %T>%
dir.create()
# Part 1: Soil drainage classes
profiles_shp <- dir_dat %>%
paste0(
.,
"/observations/profiles/Profiles_coordinates_new/",
"Profiles_coordinates_new.shp"
) %>%
vect()
# 1.1: Correct coordinates for profiles
profiles_db <- dir_dat %>%
paste0(., "/observations/profiles/DDJD2023.accdb")
con3 <- odbcConnectAccess2007(profiles_db)
profiles_DC <- sqlFetch(con3, "PROFIL") %>%
select(c(PROFILNR, DRAENKL)) %>%
drop_na() %>%
filter(DRAENKL %in% 1:5)
profiles_DC %<>% inner_join(
x = values(profiles_shp),
y = .,
by = "PROFILNR"
) %>% arrange(
PROFILNR
) %>% vect(
geom = c("x", "y"),
crs = mycrs,
keepgeom = TRUE
)
library(viridisLite)
plot(profiles_DC, "DRAENKL", col = rev(cividis(5)))
# 1.2:  Load covariates
cov_dir <- dir_dat %>% paste0(., "/covariates")
cov_files <- cov_dir %>% list.files()
cov_names <- cov_files %>% tools::file_path_sans_ext()
cov <- paste0(cov_dir, "/", cov_files) %>%
rast()
names(cov) <- cov_names
crs(cov) <- mycrs
cov_cats <- dir_code %>%
paste0(., "/cov_categories_20230712.csv") %>%
read.table(
sep = ";",
header = TRUE
)
cov_selected <- cov_cats %>%
filter(anbm_use == 1) %>%
dplyr::select(., name) %>%
unlist() %>%
unname()
cov %<>% subset(cov_selected)
# 1.3 Load texture predictions
dir_pred_all <- dir_results %>%
paste0(., "/predictions/")
tex_pred <- dir_pred_all %>% list.files(
pattern = ".tif",
full.names = TRUE
) %>%
grep(".ovr", ., names(cov), value = TRUE, invert = TRUE) %>%
grep(".aux.xml", ., names(cov), value = TRUE, invert = TRUE) %>%
grep(".vat.cpg", ., names(cov), value = TRUE, invert = TRUE) %>%
grep(".vat.dbf", ., names(cov), value = TRUE, invert = TRUE) %>%
grep(
pattern = paste(fraction_names_underscore, collapse = "|"),
.,
value = TRUE
) %>%
rast()
cov_DC <- c(cov, tex_pred)
# obs_DC <- terra::extract(
#   cov_DC,
#   profiles_DC,
#   bind = TRUE,
#   ID = FALSE
# )
dir_extr <- dir_dat %>%
paste0(., "/extracts/")
# obs_DC %>%
#   values() %>%
#   write.table(
#     file = paste0(dir_extr, "obs_DC_extr.csv"),
#     row.names = FALSE,
#     col.names = TRUE,
#     sep = ";"
#   )
obs_DC <- read.table(
paste0(dir_extr, "obs_DC_extr.csv"),
header = TRUE,
sep = ";"
)
cov_DC_names <- names(cov_DC) %>%
match(., names(obs_DC)) %>%
names(obs_DC)[.]
# 3: Extract folds and mask
dir_folds <- dir_dat %>%
paste0(., "/folds/")
file_folds_10_100m <- paste0(dir_folds, "/folds_10_100m.tif")
folds_10_100m <- rast(file_folds_10_100m)
folds_DC <- terra::extract(
x = folds_10_100m,
y = profiles_DC,
ID = FALSE,
) %>% unlist() %>% unname()
mask_LU <- paste0(dir_dat, "/layers/Mask_LU.tif") %>% rast()
mask_LU_DC <- terra::extract(
mask_LU,
profiles_DC,
ID = FALSE
) %>% unlist() %>% unname()
obs_DC %<>%
mutate(
fold = folds_DC,
mask_LU = mask_LU_DC,
UTMX = x,
UTMY = y
) %>%
filter(
!is.na(mask_LU)
)
# Calculate weights
source("f_get_dens.R")
mean_dens_DC <- nrow(obs_DC) / (43107 * 10^6)
sigma_DC <- sqrt(43107 / (nrow(obs_DC) * pi)) * 1000
dens_DC <- get_dens(obs_DC, sigma_DC)
w_DC <- mean_dens_DC / dens_DC
w_DC[w_DC > 1] <- 1
obs_DC$w <- w_DC
# Three folds (placeholder)
trdat_DC <- obs_DC %>%
mutate(
fold = ceiling(fold / 3)
) %>%
filter(fold < 4)
trdat_indices_DC <- which(obs_DC$PROFILNR %in% trdat_DC$PROFILNR)
holdout_DC <- obs_DC %>% filter(fold == 10)
holdout_indices_DC <- which(obs_DC$PROFILNR %in% holdout_DC$PROFILNR)
# List of folds
folds_DC <- lapply(
unique(trdat_DC$fold),
function(fold_i) {
out <- trdat_DC %>%
mutate(
rnum = row_number(),
) %>%
filter(!(fold %in% fold_i)) %>%
dplyr::select(., rnum) %>%
unlist() %>%
unname()
}
)
# Set up model
source("f_optimize_xgboost.R")
source("f_weighted_summaries.R")
bounds_DC <- list(
eta = c(0.1, 1),
max_depth = c(1L, 60L),
min_child_weight_sqrt = c(1, sqrt(64)),
gamma_sqrt = c(0, sqrt(40)),
colsample_bytree = c(0.1, 1),
subsample = c(0.1, 1),
colsample_bylevel = c(0.1, 1),
ogcs_index = c(1L, 7L),
total_imp = c(0.5, 1)
)
tgrid <- expand.grid(
nrounds = 10,
eta = 0.3,
max_depth = 6,
min_child_weight = 1,
gamma = 0,
colsample_bytree = 0.75,
subsample = 0.75
)
model_DC <- optimize_xgboost(
target = "DRAENKL",  # character vector (length 1), target variable.
cov_names = cov_DC_names,  # Character vector, covariate names,
data = trdat_DC, # data frame, input data
bounds_bayes = bounds_DC, # named list with bounds for bayesian opt.
bounds_pred = c(0.5, 5.5), # numeric, length 2, bounds for predicted values
cores = 19, # number cores for parallelization
trgrid = tgrid, # data frame with tuning parameters to be tested in basic model
folds = folds_DC, # list with indices, folds for cross validation
sumfun = WeightedSummary_DC, # summary function for accuracy assessment
metric = "MAEw", # character, length 1, name of evaluation metric
max_metric = FALSE, # logical, should the evaluation metric be maximized
weights = trdat_DC$w, # numeric, weights for model training and evaluation
trees_per_round = 3, # numeric, length 1, number of trees that xgboost should train in each round
obj_xgb = "reg:pseudohubererror", # character, length 1, objective function for xgboost
colsample_bylevel_basic = 0.75, # numeric, colsample_bylevel for basic model
cov_keep = NULL, # Character vector, covariates that should always be present
final_round_mult = 1,  # Multiplier for the number of rounds in the final model
seed = 321  # Random seed for model training
)
# TO DO:
# First: Predict soil drainage classes:
# Import soil drainage classes (get correct coordinates first)
# Extract covariates
# Include texture predictions as covariates
# Rearrange tiles for texture predictions to fit covariate structure
# Make summary function with weighted MAE for accuracy
# Calculate weights
# Train xgboost regression model,
# Analyse results
# Make map for test area
# Make national map
# Secondly: Predict artificially drained areas
# Import and merge data:
# - 7 km grid (original coordinates) (or new LR pts?)
# - data from orbicon
# - data from Landskontoret for Planteavl
# Aggregate relevant covariates at field scale (including new texture maps and
# soil drainage classes)
# Split into tiles
# Extract covariates
# Make summary function for weighted accuracy (or weighted AUC?)
# Calculate weights (sum of weights should be equal for drained and undrained
# points)
# Train xgboost classification model
# Analyse results
# Make map for test area
# Make national map
# 1: Start up
library(terra)
library(magrittr)
library(tools)
library(dplyr)
library(caret)
library(tibble)
library(tidyr)
library(sf)
library(exactextractr)
library(party)
library(rpart)
library(doParallel)
library(spatstat) # weights
library(RODBC)
dir_code <- getwd()
root <- dirname(dir_code)
dir_dat <- paste0(root, "/digijord_data/")
testn <- 13
mycrs <- "EPSG:25832"
fraction_names_underscore <- c(
"Clay", "Silt", "Fine_sand", "Coarse_sand", "SOC", "CaCO3"
)
# Results folder
dir_results <- dir_dat %>%
paste0(., "/results_test_", testn, "/") %T>%
dir.create()
# Part 1: Soil drainage classes
profiles_shp <- dir_dat %>%
paste0(
.,
"/observations/profiles/Profiles_coordinates_new/",
"Profiles_coordinates_new.shp"
) %>%
vect()
# 1.1: Correct coordinates for profiles
profiles_db <- dir_dat %>%
paste0(., "/observations/profiles/DDJD2023.accdb")
con3 <- odbcConnectAccess2007(profiles_db)
profiles_DC <- sqlFetch(con3, "PROFIL") %>%
select(c(PROFILNR, DRAENKL)) %>%
drop_na() %>%
filter(DRAENKL %in% 1:5)
profiles_DC %<>% inner_join(
x = values(profiles_shp),
y = .,
by = "PROFILNR"
) %>% arrange(
PROFILNR
) %>% vect(
geom = c("x", "y"),
crs = mycrs,
keepgeom = TRUE
)
library(viridisLite)
plot(profiles_DC, "DRAENKL", col = rev(cividis(5)))
# 1.2:  Load covariates
cov_dir <- dir_dat %>% paste0(., "/covariates")
cov_files <- cov_dir %>% list.files()
cov_names <- cov_files %>% tools::file_path_sans_ext()
cov <- paste0(cov_dir, "/", cov_files) %>%
rast()
names(cov) <- cov_names
crs(cov) <- mycrs
cov_cats <- dir_code %>%
paste0(., "/cov_categories_20230712.csv") %>%
read.table(
sep = ";",
header = TRUE
)
cov_selected <- cov_cats %>%
filter(anbm_use == 1) %>%
dplyr::select(., name) %>%
unlist() %>%
unname()
cov %<>% subset(cov_selected)
# 1.3 Load texture predictions
dir_pred_all <- dir_results %>%
paste0(., "/predictions/")
tex_pred <- dir_pred_all %>% list.files(
pattern = ".tif",
full.names = TRUE
) %>%
grep(".ovr", ., names(cov), value = TRUE, invert = TRUE) %>%
grep(".aux.xml", ., names(cov), value = TRUE, invert = TRUE) %>%
grep(".vat.cpg", ., names(cov), value = TRUE, invert = TRUE) %>%
grep(".vat.dbf", ., names(cov), value = TRUE, invert = TRUE) %>%
grep(
pattern = paste(fraction_names_underscore, collapse = "|"),
.,
value = TRUE
) %>%
rast()
cov_DC <- c(cov, tex_pred)
# obs_DC <- terra::extract(
#   cov_DC,
#   profiles_DC,
#   bind = TRUE,
#   ID = FALSE
# )
dir_extr <- dir_dat %>%
paste0(., "/extracts/")
# obs_DC %>%
#   values() %>%
#   write.table(
#     file = paste0(dir_extr, "obs_DC_extr.csv"),
#     row.names = FALSE,
#     col.names = TRUE,
#     sep = ";"
#   )
obs_DC <- read.table(
paste0(dir_extr, "obs_DC_extr.csv"),
header = TRUE,
sep = ";"
)
cov_DC_names <- names(cov_DC) %>%
match(., names(obs_DC)) %>%
names(obs_DC)[.]
# 3: Extract folds and mask
dir_folds <- dir_dat %>%
paste0(., "/folds/")
file_folds_10_100m <- paste0(dir_folds, "/folds_10_100m.tif")
folds_10_100m <- rast(file_folds_10_100m)
folds_DC <- terra::extract(
x = folds_10_100m,
y = profiles_DC,
ID = FALSE,
) %>% unlist() %>% unname()
mask_LU <- paste0(dir_dat, "/layers/Mask_LU.tif") %>% rast()
mask_LU_DC <- terra::extract(
mask_LU,
profiles_DC,
ID = FALSE
) %>% unlist() %>% unname()
obs_DC %<>%
mutate(
fold = folds_DC,
mask_LU = mask_LU_DC,
UTMX = x,
UTMY = y
) %>%
filter(
!is.na(mask_LU)
)
# Calculate weights
source("f_get_dens.R")
mean_dens_DC <- nrow(obs_DC) / (43107 * 10^6)
sigma_DC <- sqrt(43107 / (nrow(obs_DC) * pi)) * 1000
dens_DC <- get_dens(obs_DC, sigma_DC)
w_DC <- mean_dens_DC / dens_DC
w_DC[w_DC > 1] <- 1
obs_DC$w <- w_DC
# Three folds (placeholder)
trdat_DC <- obs_DC %>%
mutate(
fold = ceiling(fold / 3)
) %>%
filter(fold < 4)
trdat_indices_DC <- which(obs_DC$PROFILNR %in% trdat_DC$PROFILNR)
holdout_DC <- obs_DC %>% filter(fold == 10)
holdout_indices_DC <- which(obs_DC$PROFILNR %in% holdout_DC$PROFILNR)
# List of folds
folds_DC <- lapply(
unique(trdat_DC$fold),
function(fold_i) {
out <- trdat_DC %>%
mutate(
rnum = row_number(),
) %>%
filter(!(fold %in% fold_i)) %>%
dplyr::select(., rnum) %>%
unlist() %>%
unname()
}
)
# Set up model
source("f_optimize_xgboost.R")
source("f_weighted_summaries.R")
bounds_DC <- list(
eta = c(0.1, 1),
max_depth = c(1L, 60L),
min_child_weight_sqrt = c(1, sqrt(64)),
gamma_sqrt = c(0, sqrt(40)),
colsample_bytree = c(0.1, 1),
subsample = c(0.1, 1),
colsample_bylevel = c(0.1, 1),
ogcs_index = c(1L, 7L),
total_imp = c(0.5, 1)
)
tgrid <- expand.grid(
nrounds = 10,
eta = 0.3,
max_depth = 6,
min_child_weight = 1,
gamma = 0,
colsample_bytree = 0.75,
subsample = 0.75
)
model_DC <- optimize_xgboost(
target = "DRAENKL",  # character vector (length 1), target variable.
cov_names = cov_DC_names,  # Character vector, covariate names,
data = trdat_DC, # data frame, input data
bounds_bayes = bounds_DC, # named list with bounds for bayesian opt.
bounds_pred = c(0.5, 5.5), # numeric, length 2, bounds for predicted values
cores = 19, # number cores for parallelization
trgrid = tgrid, # data frame with tuning parameters to be tested in basic model
folds = folds_DC, # list with indices, folds for cross validation
sumfun = WeightedSummary_DC, # summary function for accuracy assessment
metric = "MAEw", # character, length 1, name of evaluation metric
max_metric = FALSE, # logical, should the evaluation metric be maximized
weights = trdat_DC$w, # numeric, weights for model training and evaluation
trees_per_round = 3, # numeric, length 1, number of trees that xgboost should train in each round
obj_xgb = "reg:pseudohubererror", # character, length 1, objective function for xgboost
colsample_bylevel_basic = 0.75, # numeric, colsample_bylevel for basic model
cov_keep = NULL, # Character vector, covariates that should always be present
final_round_mult = 1,  # Multiplier for the number of rounds in the final model
seed = 321  # Random seed for model training
)
model_DC
