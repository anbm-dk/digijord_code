SEGES_extr,
SINKS_extr,
profiles_extr,
forests_extr
)
obs <- cbind(obs_data, extr, folds) %>%
filter(
!is.na(UTMX),
!is.na(UTMY),
is.finite(fold),
lower > 0,
(upper < 200) | (upper == 200 & lower == 200),
!is.na(mask_LU),
!is.na(dhm2015_terraen_10m)
)
# Predict principal components
pcs_cov <- readRDS(paste0(dir_dat, "pcs_cov.rds"))
if (use_pca) {
obs_pcs <- predict(pcs_cov, obs)
obs <- cbind(obs, obs_pcs)
obs %<>% filter(
!is.na(PC1)
)
}
# Make new ID
obs %<>%
rownames_to_column() %>%
mutate(ID_new = rowname, .before = everything()) %>%
select(-rowname)
obs_v <- vect(
obs,
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
# Extract bootstrap weights
poisson_r <- paste0(dir_folds, "/poisson_100m.tif") %>% rast()
poisson_extr <- terra::extract(
poisson_r,
obs_v,
ID = FALSE
)
nboot <- ncol(poisson_extr)
if (nboot_max < nboot) {
nboot <- nboot_max
}
saveRDS(
poisson_extr,
paste0(dir_boot, "poisson_extr.rds")
)
# Select topsoil observations for plot
obs_top <- obs %>%
filter(
upper < 30,
lower > 0
)
obs_prf <- obs %>%
filter(
db == "Profile database"
)
obs_top_v <- obs_top %>% vect(geom = c("UTMX", "UTMY"))
library(tidyterra)
my_breaks <- function(x) {
x <- unique(x)
n <- 6
i <- seq(0, 1, length.out = n)
breaks <- quantile(x, i, na.rm = TRUE)
breaks <- round(breaks, digits = 1)
breaks <- unique(breaks)
if ((breaks[1] %% 1) != 0) {
breaks[1] <- breaks[1] - 0.000001
}
if ((breaks[n] %% 1) != 0) {
breaks[n] <- breaks[n] + 0.000001
}
return(breaks)
}
set.seed(1)
obs_top_plot <- obs_top_v %>%
mutate(random = runif(length(.))) %>%
arrange(random) %>%
select(any_of(fractions))
frac_labels = c(
expression("Clay"~"(%)"),
expression("Silt"~"(%)"),
expression("Fine"~"sand"~"(%)"),
expression("Coarse"~"sand"~"(%)"),
expression("SOC"~"(%)"),
expression("CaCO"[3]~"(%)")
)
library(viridisLite)
mycolors <- cividis(6) %>% rev() %>% .[-1] %>% rev()
tiff(
paste0(dir_results, "/obs_map_test", testn, ".tiff"),
width = 16,
height = 10,
units = "cm",
res = 300
)
par(oma = c(2, 2, 0, 1))
plot(
obs_top_plot,
y = 1:length(fractions),
breaks = 5,
breakby = my_breaks,
col = viridis(5),
colNA = NA,
cex = 0.1,
mar = c(0, 0, 1, 0),
main = frac_labels,
plg = list(
x = "topright", text.col = viridis(5),
fill = viridis(5),
text.font =
2)
)
try(dev.off())
try(dev.off())
par()
# 8: Set up models
if (use_pca) {
cov_selected <- c(
colnames(obs_pcs),
colnames(obs) %>%
grep('ogc_pi', ., value = TRUE)
)
} else {
cov_selected <- cov_cats %>%
filter(anbm_use == 1) %>%
dplyr::select(., name) %>%
unlist() %>%
unname()
}
# Template for custom eval
# evalerror <- function(preds, dtrain) {
#   labels <- getinfo(dtrain, "label")
#   err <- as.numeric(sum(labels != (preds > 0)))/length(labels)
#   return(list(metric = "error", value = err))
# }
source("f_weighted_summaries.R")
metrics <- rep("RMSEw", length(fractions))
metrics[fractions == "SOC"] <- "RMSEw_log"
metrics[fractions == "CaCO3"] <- "RMSEw_sqrt"
# Function to calculate point densities
qnorm(seq(0.55, 0.95, 0.1), 0, 1)
source("f_get_dens.R")
# Parameters for weights calculations
w_interval <- 10
w_increment <- 1
w_startdepth <- 0
w_maxdepth <- 200
w_depths <- seq(w_startdepth, w_maxdepth, w_increment)
w_iterations <- length(w_depths)
# Tuning grid
tgrid <- expand.grid(
nrounds = 10,
eta = 0.3,
max_depth = 6,
min_child_weight = 1,
gamma = 0,
colsample_bytree = 0.75,
subsample = 0.75
)
objectives <- c(rep("reg:squarederror", 4), rep("reg:tweedie", 2))
trees_per_round <- 1  # only one tree per round for bootstrap models
# Bayesian optimization
library(ParBayesianOptimization)
source("f_optimize_xgboost.R")
bounds <- list(
eta = c(0.1, 1),
min_child_weight_sqrt = c(1, sqrt(100)),
gamma_sqrt = c(0, sqrt(100)),
colsample_bytree = c(0.1, 1),
subsample = c(0.1, 1),
colsample_bynode = c(0.1, 1),
ogcs_index = c(1L, 7L),
total_imp = c(0.5, 1)
)
xgb_opt_stepwise <- FALSE
# 9: Train models
if (train_models) {
weights_objects <- list()  # No changed for bootstrap
models_boot<- list()
models_boot_scoreresults <- list()
models_boot_bestscores <- list()
models_boot_predictions <- list()
models_weights <- matrix(
numeric(),
nrow = nrow(obs),
ncol = length(fractions)
)
colnames(models_weights) <- fractions
models_indices <- matrix(
numeric(),
nrow = nrow(obs),
ncol = length(fractions)
)
colnames(models_indices) <- fractions
for (i in 1:length(fractions))
{
frac <- fractions[i]
print(frac)
tr_step <- 1
if (metrics[i] == "RMSEw_log") {
sumfun_i <- WeightedSummary_log
} else {
if (metrics[i] == "RMSEw_sqrt") {
sumfun_i <- WeightedSummary_sqrt
} else {
sumfun_i <- WeightedSummary
}
}
# Filter valid observations
trdat <- obs %>%
filter(
is.finite(.data[[frac]])
)
# Weighting by depth intervals
print("Calculating weights")
w_mat <- matrix(numeric(), nrow = nrow(trdat), ncol = w_iterations)
cm_mat <- matrix(numeric(), nrow = nrow(trdat), ncol = w_iterations)
for (j in 1:w_iterations)
{
upper_j <- w_depths[j] - w_interval
lower_j <- upper_j + w_interval * 2
trdat_ind <- trdat$lower > upper_j & trdat$upper < lower_j
trdat_ind[is.na(trdat_ind)] <- FALSE
trdat_j <- trdat[trdat_ind, ]
trdat_j %<>%
mutate(
thickness = lower - upper,
upper_int = case_when(
upper > upper_j ~ upper,
.default = upper_j
),
lower_int = case_when(
lower < lower_j ~ lower,
.default = lower_j
),
cm_int = case_when(
thickness == 0 ~ 1,
.default = lower_int - upper_int
)
)
cm_mat[trdat_ind, j] <- trdat_j$cm_int
# # Sigma equal to the radius of a circle with an equal area per sample
# sigma_j <- sqrt(43107 / (nrow(trdat_j) * pi)) * 1000
# Use the expected mean density as a baseline
# Do this calculation for the entire area, as a specific calculation for
# wetlands will give too much weight to these areas.
mean_dens_j <- nrow(trdat_j) / (43107 * 10^6)
# For SOC:
# Separate densities for wetlands and uplands
if (frac == "SOC" & (sum(trdat_j$db == "SINKS") > 30)) {
areas <- c(39807, 3299)
w_j <- numeric(nrow(trdat_j))
for (k in 0:1) {
# trdat_j_wl_ind <- trdat_j$cwl_10m_crisp == k
trdat_j_wl_ind <- (trdat_j$db == "SINKS") == k
trdat_j_wl_ind %<>% { ifelse(is.na(.), FALSE, .) }
trdat_jk <- trdat_j[trdat_j_wl_ind, ]
# Sigma equal to the radius of a circle with an equal area per sample
sigma_jk <- sqrt(areas[k + 1] / (nrow(trdat_jk) * pi)) * 1000
dens_jk <- get_dens(trdat_jk, sigma_jk)
w_j[trdat_j_wl_ind] <- mean_dens_j / dens_jk
}
} else {
# Sigma equal to the radius of a circle with an equal area per sample
sigma_j <- sqrt(43107 / (nrow(trdat_j) * pi)) * 1000
dens_j <- get_dens(trdat_j, sigma_j)
w_j <- mean_dens_j / dens_j
}
w_j[w_j > 1] <- 1
w_mat[trdat_ind, j] <- w_j
}
cm_mat[is.na(cm_mat)] <- 0
cm_sums <- apply(cm_mat, 1, sum)
w_cm_mat <- w_mat*cm_mat
w_cm_sums <- apply(
w_cm_mat,
1,
function(x) {
out <- sum(x, na.rm = TRUE)
return(out)
}
)
w_depth <- w_cm_sums / cm_sums
w_depth[!is.finite(w_depth)] <- 0
# Using the year as a covariate causes the model to identify the SINKS points
# based only on the sampling year, as the campaign took place over only two
# years, which were also underrepresented in the remaining training data.
if (frac == "SOC") {
w_year <- 0.99^(max(trdat$year, na.rm = TRUE) - trdat$year)
w_year %<>% { ifelse(is.na(.), 0, .) }
w_depth %<>% `*`(w_year)
}
weights_objects[[i]] <- list()
weights_objects[[i]]$cm_mat <- cm_mat
weights_objects[[i]]$cm_sums <- cm_sums
weights_objects[[i]]$w_cm_mat <- w_cm_mat
weights_objects[[i]]$w_cm_sums <- w_cm_sums
weights_objects[[i]]$w_depth <- w_depth
trdat$w <- w_depth
trdat_w_indices <- which(obs$ID_new %in% trdat$ID_new)
weights_objects[[i]]$indices <- trdat_w_indices
models_weights[trdat_w_indices, i] <- w_depth
# Three folds + 10 per cent holdout dataset
trdat %<>% mutate(
fold = ceiling(fold / 3)
)
trdat %<>% filter(fold < 4)
if (!use_all_points) {
set.seed(1)
trdat %<>% sample_n(n)
}
trdat_indices <- which(obs$ID_new %in% trdat$ID_new)
models_indices[, i] <- obs$ID_new %in% trdat$ID_new
# Add depth boundaries and SOM removal as covariates
cov_keep_i <- c("upper", "lower")
if ( !(frac %in% c("SOC", "CaCO3")) ) {
cov_keep_i %<>% c(., "SOM_removed")
}
n_const_i <- length(cov_keep_i)
cov_c_i <- cov_selected %>% c(., cov_keep_i)
# Prediction bounds
bounds_pred_i <- c(bounds_lower[i], bounds_upper[i])
# Objects for bootstrap results
dir_boot_models_i <- dir_boot_models %>%
paste0(., "/", frac, "/") %T>%
dir.create()
models_boot[[i]] <- list()
models_boot_scoreresults[[i]] <- list()
models_boot_bestscores[[i]] <- list()
models_boot_predictions[[i]] <- matrix(
numeric(),
nrow = nrow(obs),
ncol = ncol(poisson_extr)
)
# bootstrap procedure
for (bootr in 1:nboot) {
bootr_chr <- bootr %>%
str_pad(
.,
nchar(nboot),
pad = "0"
)
trdat_bootr <- trdat %>%
mutate(
weights_bootr = poisson_extr[trdat_indices, bootr],
w_combined = weights_bootr*w
) %>%
filter(w_combined > 0)
bootr_indices <- which(obs$ID_new %in% trdat_bootr$ID_new)
holdout_bootr <- obs[-bootr_indices, ]
holdout_indices <- which(obs$ID_new %in% holdout_bootr$ID_new)
# List of folds
folds_bootr <- lapply(
unique(trdat_bootr$fold),
function(x) {
out <- trdat_bootr %>%
mutate(
is_j = fold != x,
rnum = row_number(),
ind_j = is_j * rnum
) %>%
filter(ind_j != 0) %>%
dplyr::select(., ind_j) %>%
unlist() %>%
unname()
}
)
# Bayes optimization
foreach::registerDoSEQ()
showConnections()
model_bootr <- optimize_xgboost(
target = frac,  # character vector (length 1), target variable.
cov_names = cov_c_i,  # Character vector, covariate names,
data = trdat_bootr, # data frame, input data
bounds_bayes = bounds, # named list with bounds for bayesian opt.
bounds_pred = bounds_pred_i, # numeric, length 2, bounds for predicted values
cores = 19, # number cores for parallelization
trgrid = tgrid, # data frame with tuning parameters to be tested in basic model
folds = folds_bootr, # list with indices, folds for cross validation
sumfun = sumfun_i, # summary function for accuracy assessment
metric = metrics[i], # character, length 1, name of evaluation metric
max_metric = FALSE, # logical, should the evaluation metric be maximized
weights = trdat_bootr$w_combined, # numeric, weights for model training and evaluation
trees_per_round = 1, # numeric, length 1, number of trees that xgboost should train in each round
obj_xgb = objectives[i], # character, length 1, objective function for xgboost
colsample_bynode_basic = 0.75, # numeric, colsample_bynode for basic model
cov_keep = cov_keep_i, # Character vector, covariates that should always be present
final_round_mult = 1,  # Multiplier for the number of rounds in the final model
maxd = 10^3, # Maximum depth for optimized models
seed = 321,  # Random seed for model training,
classprob = FALSE
)
models_boot_scoreresults[[i]][[bootr]] <- model_bootr$bayes_results
models_boot_bestscores[[i]][[bootr]] <- model_bootr$best_scores
print(
models_boot_bestscores[[i]][[bootr]]
)
models_boot[[i]][[bootr]] <- model_bootr$model
# End of optimization
model_bootr_pred <- model_bootr$model$pred %>%
arrange(rowIndex) %>%
distinct(rowIndex, .keep_all = TRUE) %>%
dplyr::select(., pred) %>%
unlist() %>%
unname()
models_boot_predictions[[i]][bootr_indices, bootr] <- model_bootr_pred
models_boot_predictions[[i]][-bootr_indices, bootr] <- predict_passna(
models_boot[[i]][[bootr]],
holdout_bootr,
n_const = n_const_i
)
saveRDS(
models_boot[[i]][[bootr]],
paste0(dir_boot_models_i, "/model_", frac, "_", bootr_chr, ".rds")
)
}
models_boot_bestscores[[i]] %<>%
bind_rows() %>%
mutate(
frac = frac
)
}
# End of model training
names(weights_objects) <- fractions
saveRDS(
weights_objects,
paste0(dir_results, "/weights_objects.rds")
)
saveRDS(
models_boot_scoreresults,
paste0(dir_boot, "/models_boot_scoreresults.rds")
)
models_boot_bestscores %<>%
bind_rows()
saveRDS(
models_boot_bestscores,
paste0(dir_boot, "/models_boot_bestscores.rds")
)
write.table(
models_boot_bestscores,
file = paste0(dir_boot, "/models_boot_bestscores.csv"),
sep = ";",
row.names = FALSE
)
write.table(
models_weights,
file = paste0(dir_results, "/models_weights.csv"),
sep = ";",
row.names = FALSE
)
write.table(
models_indices,
file = paste0(dir_results, "/models_indices.csv"),
sep = ";",
row.names = FALSE
)
saveRDS(
models_boot_predictions,
paste0(dir_boot, "/models_boot_predictions.rds")
)
} else {
# Load existing models
models_boot <- lapply(
1:length(fractions),
function(x) {
model_files <- fractions[x] %>%
paste0(dir_boot_models, "/", ., "/") %>%
list.files(full.names = TRUE)
out <- lapply(
model_files,
function(x2) {
out2 <- readRDS(x2)
}
)
return(out)
}
)
weights_objects <- dir_results %>%
paste0(., "/weights_objects.rds") %>%
readRDS()
models_boot_scoreresults <- dir_boot %>%
paste0(., "/models_boot_scoreresults.rds") %>%
readRDS()
models_boot_bestscores <- dir_boot %>%
paste0(., "/models_boot_bestscores.rds") %>%
readRDS()
models_weights <- dir_results %>%
paste0(., "/models_weights.csv") %>%
read.table(
., header = TRUE,
sep = ";"
)
models_indices <- dir_results %>%
paste0(., "/models_indices.csv") %>%
read.table(
., header = TRUE,
sep = ";"
)
models_boot_predictions <- dir_boot %>%
paste0(., "/models_boot_predictions.rds") %>%
readRDS()
}
warnings()
trdat_bootr
trdat_bootr$w_combined
trdat_bootr$w_combined %>% plot()
trdat_bootr$coarse_sand %>% plot()
model_bootr
