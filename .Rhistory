colour = 'black'),
axis.title.x = element_blank(),
axis.text.y = element_text(colour = 'black'),
panel.grid.major = element_line(color = 'grey'),
panel.grid.minor = element_blank(),
panel.border = element_rect(linewidth = 1)
)
try(dev.off())
# 1: Start up
library(terra)
library(magrittr)
library(dplyr)
library(stringr)
dir_code <- getwd()
root <- dirname(dir_code)
dir_dat <- paste0(root, "/digijord_data/")
dir_cov <- dir_dat %>% paste0(., "/covariates")
mycrs <- "EPSG:25832"
dir_tiles <- dir_dat %>%
paste0(., "/tiles_591/")
dir_mask_tiles <- dir_dat %>%
paste0(., "/layers/Mask_LU_tiles/")
# Load tile shape polygons
tile_shapes <- dir_tiles %>%
paste0(., "/tiles.shp") %>%
vect()
# Find covariates
cov_files <- dir_cov %>%
list.files(
pattern = ".tif",
full.names = TRUE
)
# Select relevant covariates
cov_cats <- dir_code %>%
paste0(., "/cov_categories_20231110.csv") %>%
read.table(
sep = ",",
header = TRUE
)
cov_names_all <- cov_files %>%
basename() %>%
tools::file_path_sans_ext(.)
cov_selected <- cov_cats %>%
filter(anbm_use == 1) %>%
select(name) %>%
unlist() %>%
unname()
cov_files_selected <- cov_files[cov_names_all %in% cov_selected]
# Make names for tiles
max_char <- length(tile_shapes) %>%
1:. %>%
as.character() %>%
nchar() %>%
max()
tile_numbers <- length(tile_shapes) %>%
1:. %>%
str_pad(
.,
max_char,
pad = "0"
)
# Cropping function
source("f_cropstack.R")
cov_files_selected
cov_files_notogc <- cov_files_selected %>%
grep('ogc_pi', ., value = TRUE, invert = TRUE)
cov_files_ogc <- cov_files_selected %>%
grep('ogc_pi', ., value = TRUE)
cov_files_ogc <- cov_files_selected %>%
grep('ogc_pi', ., value = TRUE)
library(parallel)
numCores <- detectCores()
numCores
showConnections()
cl <- makeCluster(numCores)
clusterEvalQ(
cl,
{
library(terra)
library(magrittr)
library(dplyr)
library(tools)
}
)
clusterExport(
cl,
c(
"dir_dat",
"dir_tiles",
"dir_code",
"tile_numbers",
"cov_files_ogc",
"dir_mask_tiles"
)
)
parSapplyLB(
cl,
1:length(tile_shapes),
function(j) {
tmpfolder <- paste0(dir_dat, "/Temp/")
terraOptions(memfrac = 0.02, tempdir = tmpfolder)
dir_tile_j <- dir_tiles %>%
paste0(., "/tile_", tile_numbers[j], "/") %T>%
dir.create()
my_ext <- paste0(
dir_mask_tiles, "/Mask_LU_tile_", tile_numbers[j], ".tif"
) %>%
rast()
source(paste0(dir_code, "/f_cropstack.R"))
cropstack(
x = cov_files_ogc,
y = my_ext,
folder = dir_tile_j,
mask = FALSE
)
}
)
stopCluster(cl)
foreach::registerDoSEQ()
rm(cl)
# library(Cubist)
library(terra)
library(magrittr)
library(tools)
library(dplyr)
library(caret)
library(tibble)
library(tidyr)
library(xgboost)
library(doParallel)
library(spatstat) # weights
dir_code <- getwd()
root <- dirname(dir_code)
dir_dat <- paste0(root, "/digijord_data/")
source("f_predict_passna.R")
train_models <- TRUE
# To do:
# Pdp with depth
# Profile examples
# Test 1 - 8: Cubist.
# Test 8: New covariates (chelsa, river valley bottoms, hillyness).
# Test 9: xgboost.
# Test 10: Predicted row and column (poor accuracy).
# Test 11: Fever data, excluding water, sealed areas and urban areas.
# Test 12: Depth boundaries as covariates, stepwise xgb optimization.
# Test 13: Bayesian optimization.
# Test 14: Fix mistake in covariate selection, new optimization function.
# Categorical covariates now have fuzzy boundaries.
# Filled gaps in bare soil composite.
# Using colsample_bynode instead of colsample_bylevel.
# Using principal components analysis for covariates
testn <- 14
mycrs <- "EPSG:25832"
# Results folder
dir_results <- dir_dat %>%
paste0(., "/results_test_", testn, "/") %T>%
dir.create()
# 2: Load observations
dir_obs_proc <- dir_dat %>%
paste0(., "/observations/processed/")
dsc <- dir_obs_proc %>%
paste0(., "dsc.csv") %>%
read.table(
header = TRUE,
sep = ";"
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
SEGES <- dir_obs_proc %>%
paste0(., "SEGES.csv") %>%
read.table(
header = TRUE,
sep = ";"
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
SINKS <- dir_obs_proc %>%
paste0(., "SINKS.csv") %>%
read.table(
header = TRUE,
sep = ";"
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
profiles_texture <- dir_obs_proc %>%
paste0(., "profiles_texture.csv") %>%
read.table(
header = TRUE,
sep = ";"
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
forest_samples <- dir_obs_proc %>%
paste0(., "forest_samples.csv") %>%
read.table(
header = TRUE,
sep = ";"
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
# 3: Load folds
dir_folds <- dir_dat %>%
paste0(., "/folds/")
dsc_folds <- dir_folds %>%
paste0(., "dsc_folds.csv") %>%
read.table(
header = TRUE,
sep = ";"
)
SEGES_folds <- dir_folds %>%
paste0(., "SEGES_folds.csv") %>%
read.table(
header = TRUE,
sep = ";"
)
SINKS_folds <- dir_folds %>%
paste0(., "SINKS_folds.csv") %>%
read.table(
header = TRUE,
sep = ";"
)
profiles_folds <- dir_folds %>%
paste0(., "profiles_folds.csv") %>%
read.table(
header = TRUE,
sep = ";"
) %>%
right_join(values(profiles_texture)) %>%
select(lyr.1)
forest_folds <- dir_folds %>%
paste0(., "forest_folds.csv") %>%
read.table(
header = TRUE,
sep = ";"
)
# 4: Load covariate data
dir_cov <- dir_dat %>% paste0(., "/covariates")
cov_cats <- dir_code %>%
paste0(., "/cov_categories_20231110.csv") %>%
read.table(
sep = ",",
header = TRUE
)
cov_files <- dir_cov %>% list.files()
cov_names <- cov_files %>% tools::file_path_sans_ext()
cov_names %>%
write.table(
paste0("cov_names_", Sys.Date(), ".csv")
)
cov_names[!cov_names %in% cov_cats$name]
# 5: Load extracted covariates
dir_extr <- dir_dat %>%
paste0(., "/extracts/")
usebuffer <- FALSE
if (usebuffer) {
dsc_extr <- dir_extr %>%
paste0(., "/buffer_dsc_extr.csv") %>%
read.table(
header = TRUE,
sep = ";"
)
SEGES_extr <- dir_extr %>%
paste0(., "/buffer_SEGES_extr.csv") %>%
read.table(
header = TRUE,
sep = ";"
)
} else {
dsc_extr <- dir_extr %>%
paste0(., "/dsc_extr.rds") %>%
readRDS()
SEGES_extr <- dir_extr %>%
paste0(., "/SEGES_extr.rds") %>%
readRDS()
}
SINKS_extr <- dir_extr %>%
paste0(., "/SINKS_extr.rds") %>%
readRDS()
profiles_extr <- dir_extr %>%
paste0(., "profiles_extr.rds") %>%
readRDS() %>%
right_join(values(profiles_texture)) %>%
select(any_of(cov_names))
SINKS_extr <- dir_extr %>%
paste0(., "/SINKS_extr.rds") %>%
readRDS()
forests_extr <- dir_extr %>%
paste0(., "/forests_extr.rds") %>%
readRDS()
# 6: Merge data
obs_v <- list(dsc, SEGES, SINKS, profiles_texture, forest_samples) %>%
vect()
# Extract mask values for all the observations
mask_LU <- paste0(dir_dat, "/layers/Mask_LU.tif") %>% rast()
mask_LU_extr <- terra::extract(
mask_LU,
obs_v,
ID = FALSE
)
mask_LU_extr %<>% unlist() %>% unname()
obs_data <- obs_v %>%
values() %>%
mutate(
# logSOC = log(SOC),
# logCaCO3 = log(CaCO3),
year = date %>%
as.character() %>%
substr(start = 1, stop = 4) %>%
as.numeric(),
mask_LU = mask_LU_extr
)
# fractions <- c("clay", "silt", "fine_sand", "coarse_sand", "logSOC", "logCaCO3")
fractions_alt <- c("clay", "silt", "fine_sand", "coarse_sand", "SOC", "CaCO3")
fractions <- fractions_alt
fraction_names <- c(
"Clay", "Silt", "Fine sand", "Coarse sand", "SOC", "CaCO3"
)
bounds_lower <- rep(0, 6)
bounds_upper <- rep(100, 6)
# 7: Make training data
folds <- bind_rows(
dsc_folds,
SEGES_folds,
SINKS_folds,
profiles_folds,
forest_folds
)
names(folds) <- "fold"
extr <- bind_rows(
dsc_extr,
SEGES_extr,
SINKS_extr,
profiles_extr,
forests_extr
)
obs <- cbind(obs_data, extr, folds) %>%
filter(
!is.na(UTMX),
!is.na(UTMY),
!is.na(mask_LU),
is.finite(fold)
)
# Make new ID
obs %<>%
rownames_to_column() %>%
mutate(ID_new = rowname, .before = everything()) %>%
select(-rowname)
# Predict principal components
use_pca <- TRUE
pcs_cov <- readRDS(paste0(dir_dat, "pcs_cov.rds"))
if (use_pca) {
obs_pcs <- predict(pcs_cov, obs)
obs <- cbind(obs, obs_pcs)
}
# Select topsoil observations for plot
obs_top <- obs %>%
filter(
upper < 30,
lower > 0
)
obs_prf <- obs %>%
filter(
db == "Profile database"
)
obs_top_v <- obs_top %>% vect(geom = c("UTMX", "UTMY"))
library(tidyterra)
my_breaks <- function(x) {
x <- unique(x)
n <- 6
i <- seq(0, 1, length.out = n)
breaks <- quantile(x, i, na.rm = TRUE)
breaks <- round(breaks, digits = 1)
breaks <- unique(breaks)
if ((breaks[1] %% 1) != 0) {
breaks[1] <- breaks[1] - 0.000001
}
if ((breaks[n] %% 1) != 0) {
breaks[n] <- breaks[n] + 0.000001
}
return(breaks)
}
set.seed(1)
obs_top_plot <- obs_top_v %>%
mutate(random = runif(length(.))) %>%
arrange(random) %>%
select(any_of(fractions))
frac_labels = c(
expression("Clay"~"(%)"),
expression("Silt"~"(%)"),
expression("Fine"~"sand"~"(%)"),
expression("Coarse"~"sand"~"(%)"),
expression("SOC"~"(%)"),
expression("CaCO"[3]~"(%)")
)
library(viridisLite)
mycolors <- cividis(6) %>% rev() %>% .[-1] %>% rev()
tiff(
paste0(dir_results, "/obs_map_test", testn, ".tiff"),
width = 16,
height = 10,
units = "cm",
res = 300
)
par(oma = c(2, 2, 0, 1))
plot(
obs_top_plot,
y = 1:length(fractions),
breaks = 5,
breakby = my_breaks,
col = viridis(5),
colNA = NA,
cex = 0.1,
mar = c(0, 0, 1, 0),
main = frac_labels,
plg = list(
x = "topright", text.col = viridis(5),
fill = viridis(5),
text.font =
2)
)
try(dev.off())
try(dev.off())
par()
# 8: Set up models
if (use_pca) {
cov_selected <- c(
colnames(obs_pcs),
colnames(obs) %>%
grep('ogc_pi', ., value = TRUE)
)
} else {
cov_selected <- cov_cats %>%
filter(anbm_use == 1) %>%
dplyr::select(., name) %>%
unlist() %>%
unname()
}
# Template for custom eval
# evalerror <- function(preds, dtrain) {
#   labels <- getinfo(dtrain, "label")
#   err <- as.numeric(sum(labels != (preds > 0)))/length(labels)
#   return(list(metric = "error", value = err))
# }
source("f_weighted_summaries.R")
metrics <- rep("RMSEw", length(fractions))
metrics[fractions == "SOC"] <- "RMSEw_log"
metrics[fractions == "CaCO3"] <- "RMSEw_sqrt"
# Function to calculate point densities
qnorm(seq(0.55, 0.95, 0.1), 0, 1)
source("f_get_dens.R")
# Parameters for weights calculations
w_interval <- 10
w_increment <- 1
w_startdepth <- 0
w_maxdepth <- 200
w_depths <- seq(w_startdepth, w_maxdepth, w_increment)
w_iterations <- length(w_depths)
# Tuning grid
tgrid <- expand.grid(
nrounds = 10,
eta = 0.3,
max_depth = 6,
min_child_weight = 1,
gamma = 0,
colsample_bytree = 0.75,
subsample = 0.75
)
objectives <- c(rep("reg:squarederror", 4), rep("reg:tweedie", 2))
trees_per_round <- 10
# Bayesian optimization
library(ParBayesianOptimization)
source("f_optimize_xgboost.R")
bounds <- list(
eta = c(0.1, 1),
min_child_weight_sqrt = c(1, sqrt(100)),
gamma_sqrt = c(0, sqrt(100)),
colsample_bytree = c(0.1, 1),
subsample = c(0.1, 1),
colsample_bynode = c(0.1, 1),
ogcs_index = c(1L, 7L),
total_imp = c(0.5, 1)
)
xgb_opt_stepwise <- FALSE
# Small random sample for testing
# Remember to include full dataset in the final model
n <- 2000
use_all_points <- FALSE
use_all_points <- TRUE
obs
obs$db
obs$db %>% unique()
obs$db == "SINKS"
(obs$db == "SINKS") %>% plot()
((obs$db == "SINKS") == 0) %>% plot()
sum(obs$db == "SINKS")) > 30
sum(obs$db == "SINKS") > 30
(sum(obs$db == "SINKS") > 30)
