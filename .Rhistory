arrange(random) %>%
select(any_of(fractions))
frac_labels = c(
expression("Clay"~"(%)"),
expression("Silt"~"(%)"),
expression("Fine"~"sand"~"(%)"),
expression("Coarse"~"sand"~"(%)"),
expression("SOC"~"(%)"),
expression("CaCO"[3]~"(%)")
)
library(viridisLite)
mycolors <- cividis(6) %>% rev() %>% .[-1] %>% rev()
tiff(
paste0(dir_results, "/obs_map_test", testn, ".tiff"),
width = 16,
height = 10,
units = "cm",
res = 300
)
par(oma = c(2, 2, 0, 1))
plot(
obs_top_plot,
y = 1:length(fractions),
breaks = 5,
breakby = my_breaks,
col = viridis(5),
colNA = NA,
cex = 0.1,
mar = c(0, 0, 1, 0),
main = frac_labels,
plg = list(
x = "topright", text.col = viridis(5),
fill = viridis(5),
text.font =
2)
)
try(dev.off())
try(dev.off())
par()
# 8: Set up models
if (use_pca) {
cov_selected <- c(
colnames(obs_pcs),
colnames(obs) %>%
grep('ogc_pi', ., value = TRUE)
)
} else {
cov_selected <- cov_cats %>%
filter(anbm_use == 1) %>%
dplyr::select(., name) %>%
unlist() %>%
unname()
}
# Template for custom eval
# evalerror <- function(preds, dtrain) {
#   labels <- getinfo(dtrain, "label")
#   err <- as.numeric(sum(labels != (preds > 0)))/length(labels)
#   return(list(metric = "error", value = err))
# }
source("f_weighted_summaries.R")
metrics <- rep("RMSEw", length(fractions))
metrics[fractions == "SOC"] <- "RMSEw_log"
metrics[fractions == "CaCO3"] <- "RMSEw_sqrt"
# Function to calculate point densities
qnorm(seq(0.55, 0.95, 0.1), 0, 1)
source("f_get_dens.R")
# Parameters for weights calculations
w_interval <- 10
w_increment <- 1
w_startdepth <- 0
w_maxdepth <- 200
w_depths <- seq(w_startdepth, w_maxdepth, w_increment)
w_iterations <- length(w_depths)
# Tuning grid
tgrid <- expand.grid(
nrounds = 10,
eta = 0.3,
max_depth = 6,
min_child_weight = 1,
gamma = 0,
colsample_bytree = 0.75,
subsample = 0.75
)
objectives <- c(rep("reg:squarederror", 4), rep("reg:tweedie", 2))
trees_per_round <- 1  # only one tree per round for bootstrap models
# Bayesian optimization
library(ParBayesianOptimization)
source("f_optimize_xgboost.R")
bounds <- list(
eta = c(0.1, 1),
min_child_weight_sqrt = c(1, sqrt(100)),
gamma_sqrt = c(0, sqrt(100)),
colsample_bytree = c(0.1, 1),
subsample = c(0.1, 1),
colsample_bynode = c(0.1, 1),
ogcs_index = c(1L, 7L),
total_imp = c(0.1, 1)
)
xgb_opt_stepwise <- FALSE
# 9: Train models
if (train_models) {
weights_objects <- list()  # Not changed for bootstrap
models_boot <- list()
models_boot_scoreresults <- list()
models_boot_bestscores <- list()
models_boot_predictions <- list()
models_weights <- list()
models_indices <- list() #####
for (i in 1:length(fractions))
# for (i in 4:length(fractions))
{
frac <- fractions[i]
print(frac)
tr_step <- 1
if (metrics[i] == "RMSEw_log") {
sumfun_i <- WeightedSummary_log
} else {
if (metrics[i] == "RMSEw_sqrt") {
sumfun_i <- WeightedSummary_sqrt
} else {
sumfun_i <- WeightedSummary
}
}
# Filter valid observations
trdat <- obs %>%
filter(
is.finite(.data[[frac]])
)
# Weighting by depth intervals
print("Calculating weights")
w_mat <- matrix(numeric(), nrow = nrow(trdat), ncol = w_iterations)
cm_mat <- matrix(numeric(), nrow = nrow(trdat), ncol = w_iterations)
for (j in 1:w_iterations)
{
upper_j <- w_depths[j] - w_interval
lower_j <- upper_j + w_interval * 2
trdat_ind <- trdat$lower > upper_j & trdat$upper < lower_j
trdat_ind[is.na(trdat_ind)] <- FALSE
trdat_j <- trdat[trdat_ind, ]
trdat_j %<>%
mutate(
thickness = lower - upper,
upper_int = case_when(
upper > upper_j ~ upper,
.default = upper_j
),
lower_int = case_when(
lower < lower_j ~ lower,
.default = lower_j
),
cm_int = case_when(
thickness == 0 ~ 1,
.default = lower_int - upper_int
)
)
cm_mat[trdat_ind, j] <- trdat_j$cm_int
# # Sigma equal to the radius of a circle with an equal area per sample
# sigma_j <- sqrt(43107 / (nrow(trdat_j) * pi)) * 1000
# Use the expected mean density as a baseline
# Do this calculation for the entire area, as a specific calculation for
# wetlands will give too much weight to these areas.
mean_dens_j <- nrow(trdat_j) / (43107 * 10^6)
# For SOC:
# Separate densities for wetlands and uplands
if (frac == "SOC" & (sum(trdat_j$db == "SINKS") > 30)) {
areas <- c(39807, 3299)
w_j <- numeric(nrow(trdat_j))
for (k in 0:1) {
# trdat_j_wl_ind <- trdat_j$cwl_10m_crisp == k
trdat_j_wl_ind <- (trdat_j$db == "SINKS") == k
trdat_j_wl_ind %<>% { ifelse(is.na(.), FALSE, .) }
trdat_jk <- trdat_j[trdat_j_wl_ind, ]
# Sigma equal to the radius of a circle with an equal area per sample
sigma_jk <- sqrt(areas[k + 1] / (nrow(trdat_jk) * pi)) * 1000
dens_jk <- get_dens(trdat_jk, sigma_jk)
w_j[trdat_j_wl_ind] <- mean_dens_j / dens_jk
}
} else {
# Sigma equal to the radius of a circle with an equal area per sample
sigma_j <- sqrt(43107 / (nrow(trdat_j) * pi)) * 1000
dens_j <- get_dens(trdat_j, sigma_j)
w_j <- mean_dens_j / dens_j
}
w_j[w_j > 1] <- 1
w_mat[trdat_ind, j] <- w_j
}
cm_mat[is.na(cm_mat)] <- 0
cm_sums <- apply(cm_mat, 1, sum)
w_cm_mat <- w_mat*cm_mat
w_cm_sums <- apply(
w_cm_mat,
1,
function(x) {
out <- sum(x, na.rm = TRUE)
return(out)
}
)
w_depth <- w_cm_sums / cm_sums
w_depth[!is.finite(w_depth)] <- 0
# Using the year as a covariate causes the model to identify the SINKS points
# based only on the sampling year, as the campaign took place over only two
# years, which were also underrepresented in the remaining training data.
if (frac == "SOC") {
w_year <- 0.99^(max(trdat$year, na.rm = TRUE) - trdat$year)
w_year %<>% { ifelse(is.na(.), 0, .) }
w_depth %<>% `*`(w_year)
}
weights_objects[[i]] <- list()
weights_objects[[i]]$cm_mat <- cm_mat
weights_objects[[i]]$cm_sums <- cm_sums
weights_objects[[i]]$w_cm_mat <- w_cm_mat
weights_objects[[i]]$w_cm_sums <- w_cm_sums
weights_objects[[i]]$w_depth <- w_depth
trdat$w <- w_depth
trdat_w_indices <- which(obs$ID_new %in% trdat$ID_new)
weights_objects[[i]]$indices <- trdat_w_indices
models_weights[[i]] <- numeric(nrow(obs))
models_weights[[i]][trdat_w_indices] <- w_depth
# Three folds + 10 per cent holdout dataset
trdat %<>% mutate(
fold = ceiling(fold / 3)
)
trdat %<>% filter(fold < 4)
if (!use_all_points) {
set.seed(1)
trdat %<>% sample_n(n)
}
trdat_indices <- which(obs$ID_new %in% trdat$ID_new)
models_indices[[i]] <- obs$ID_new %in% trdat$ID_new
# Add depth boundaries and SOM removal as covariates
cov_keep_i <- c("upper", "lower")
if ( !(frac %in% c("SOC", "CaCO3")) ) {
cov_keep_i %<>% c(., "SOM_removed")
}
n_const_i <- length(cov_keep_i)
cov_c_i <- cov_selected %>% c(., cov_keep_i)
# Prediction bounds
bounds_pred_i <- c(bounds_lower[i], bounds_upper[i])
# Objects for bootstrap results
dir_boot_models_i <- dir_boot_models %>%
paste0(., "/", frac, "/") %T>%
dir.create()
models_boot[[i]] <- list()
models_boot_scoreresults[[i]] <- list()
models_boot_bestscores[[i]] <- list()
models_boot_predictions[[i]] <- matrix(
numeric(),
nrow = nrow(obs),
ncol = ncol(poisson_extr)
)
# bootstrap procedure
print("Training models")
for (bootr in 1:nboot) {
bootr_chr <- bootr %>%
str_pad(
.,
nchar(nboot),
pad = "0"
)
trdat_bootr <- trdat %>%
mutate(
weights_bootr = poisson_extr[trdat_indices, bootr],
w_combined = weights_bootr*w
) %>%
filter(w_combined > 0)
bootr_indices <- which(obs$ID_new %in% trdat_bootr$ID_new)
holdout_bootr <- obs[-bootr_indices, ]
holdout_indices <- which(obs$ID_new %in% holdout_bootr$ID_new)
# List of folds
folds_bootr <- lapply(
unique(trdat_bootr$fold),
function(x) {
out <- trdat_bootr %>%
mutate(
is_j = fold != x,
rnum = row_number(),
ind_j = is_j * rnum
) %>%
filter(ind_j != 0) %>%
dplyr::select(., ind_j) %>%
unlist() %>%
unname()
}
)
# Bayes optimization
foreach::registerDoSEQ()
showConnections()
model_bootr <- optimize_xgboost(
target = frac,  # character vector (length 1), target variable.
cov_names = cov_c_i,  # Character vector, covariate names,
data = trdat_bootr, # data frame, input data
bounds_bayes = bounds, # named list with bounds for bayesian opt.
bounds_pred = bounds_pred_i, # numeric, length 2, bounds for predicted values
cores = 19, # number cores for parallelization
trgrid = tgrid, # data frame with tuning parameters to be tested in basic model
folds = folds_bootr, # list with indices, folds for cross validation
sumfun = sumfun_i, # summary function for accuracy assessment
metric = metrics[i], # character, length 1, name of evaluation metric
max_metric = FALSE, # logical, should the evaluation metric be maximized
weights = trdat_bootr$w_combined, # numeric, weights for model training and evaluation
trees_per_round = 1, # numeric, length 1, number of trees that xgboost should train in each round
obj_xgb = objectives[i], # character, length 1, objective function for xgboost
colsample_bynode_basic = 0.75, # numeric, colsample_bynode for basic model
cov_keep = cov_keep_i, # Character vector, covariates that should always be present
final_round_mult = 1,  # Multiplier for the number of rounds in the final model
maxd = 10^3, # Maximum depth for optimized models
seed = 321,  # Random seed for model training,
classprob = FALSE
)
models_boot_scoreresults[[i]][[bootr]] <- model_bootr$bayes_results
models_boot_bestscores[[i]][[bootr]] <- model_bootr$best_scores
print(
models_boot_bestscores[[i]][[bootr]]
)
models_boot[[i]][[bootr]] <- model_bootr$model
# End of optimization
model_bootr_pred <- model_bootr$model$pred %>%
arrange(rowIndex) %>%
distinct(rowIndex, .keep_all = TRUE) %>%
dplyr::select(., pred) %>%
unlist() %>%
unname()
models_boot_predictions[[i]][bootr_indices, bootr] <- model_bootr_pred
models_boot_predictions[[i]][-bootr_indices, bootr] <- predict_passna(
models_boot[[i]][[bootr]],
holdout_bootr,
n_const = n_const_i
)
saveRDS(
models_boot[[i]][[bootr]],
paste0(dir_boot_models_i, "/model_", frac, "_", bootr_chr, ".rds")
)
}
# End of model training
models_boot_bestscores[[i]] %<>%
bind_rows() %>%
mutate(
frac = frac
)
saveRDS(
weights_objects[[i]],
paste0(dir_results, "/weights_objects_", frac, ".rds")
)
saveRDS(
models_boot_scoreresults[[i]],
paste0(dir_boot, "/models_boot_scoreresults_", frac, ".rds")
)
saveRDS(
models_boot_bestscores[[i]],
paste0(dir_boot, "/models_boot_bestscores_", frac, ".rds")
)
saveRDS(
models_weights[[i]],
file = paste0(dir_results, "/models_weights_", frac, ".rds")
)
saveRDS(
models_indices[[i]],
file = paste0(dir_results, "/models_indices_", frac, ".csv"),
)
saveRDS(
models_boot_predictions[[i]],
paste0(dir_boot, "/models_boot_predictions_", frac, ".rds")
)
}
} else {
# Load existing models
models_boot <- lapply(
1:length(fractions),
function(x) {
model_files <- fractions[x] %>%
paste0(dir_boot_models, "/", ., "/") %>%
list.files(full.names = TRUE)
out <- lapply(
model_files,
function(x2) {
out2 <- readRDS(x2)
}
)
return(out)
}
)
weights_objects <- list()
models_boot_scoreresults <- list()
models_boot_bestscores <- list()
models_weights <- list()
models_indices <- list()
models_boot_predictions <- list()
for (i in 1:length(fractions)) {
frac <- fractions[i]
weights_objects[[i]] <- dir_results %>%
paste0(., "/weights_objects_", frac, ".rds") %>%
readRDS()
models_boot_scoreresults[[i]] <- dir_boot %>%
paste0(., "/models_boot_scoreresults_", frac, ".rds") %>%
readRDS()
models_boot_bestscores[[i]] <- dir_boot %>%
paste0(., "/models_boot_bestscores_", frac, ".rds") %>%
readRDS()
models_weights[[i]] <- dir_results %>%
paste0(., "/models_weights_", frac, ".csv") %>%
readRDS()
models_indices[[i]] <- dir_results %>%
paste0(., "/models_indices_", frac, ".csv") %>%
readRDS()
models_boot_predictions[[i]] <- dir_boot %>%
paste0(., "/models_boot_predictions_", frac, ".rds") %>%
readRDS()
}
}
trdat_bootr
showConnections()
makePSOCKcluster()
?makePSOCKcluster
?registerDoParallel
?stopCluster
?showConnections
?makeCluster
?registerDoSEQ
?makePSOCKcluster
?registerDoParallel
model_bootr
varImp(model_bootr$model)
?bayesOpt
stopImplicitCluster()
?filter
?trainControl
library(doMC)
?trainControl
trdat_bootr
trdat_bootr %>% apply(2, function(x) {sum(is.na(x))})
trdat_bootr %>% filter(is.na(SOM_removed))
?registerDoParallel
View(model_bootr)
model_bootr
sessionInfo()
?rownames_to_column
?arrange
?mutate
showConnections()
getwd()
sumfun_i
closeAllConnections()
showConnections()
paste0(dir_boot_models_i, "/model_", frac, "_", bootr_chr, ".rds")
exists(paste0(dir_boot_models_i, "/model_", frac, "_", bootr_chr, ".rds"))
paste0(dir_boot_models_i, "/model_", frac, "_", bootr_chr, ".rds") %>% exists()
?exists
paste0(dir_boot_models_i, "/model_", frac, "_", bootr_chr, ".rds") %>% file.exists()
models_boot_scoreresults
saveRDS(
models_boot_scoreresults[[i]],
paste0(dir_boot, "/models_boot_scoreresults_", frac, ".rds")
)
saveRDS(
models_boot_bestscores[[i]],
paste0(dir_boot, "/models_boot_bestscores_", frac, ".rds")
)
saveRDS(
models_boot_predictions[[i]],
paste0(dir_boot, "/models_boot_predictions_", frac, ".rds")
)
models_boot_bestscores
models_boot_predictions
str(models_boot_bestscores)
str(models_boot_bestscores[[1]])
dir_boot_models_i
dir_boot_models_i %>% list.files()
dir_boot_models_i %>% list.files() %>% length()
n_models_exist <- dir_boot_models_i %>% list.files() %>% length()
n_models_exist < nboot
bestscores_filename <- paste0(
dir_boot, "/models_boot_bestscores_", frac, ".rds"
)
boot_predictions_filename <- paste0(
dir_boot, "/models_boot_predictions_", frac, ".rds"
)
n_models_exist
length(models_boot_bestscores[[i]])
length(models_boot_bestscores[[1]])
is.data.frame(models_boot_bestscores[[1]])
ncol(models_boot_bestscores[[1]])
nrow(models_boot_bestscores[[1]])
models_boot_predictions[[i]] %>% colSums()
models_boot_predictions[[i]] %>% colSums() %>% is.na()
models_boot_predictions[[i]] %>% colSums() %>% is.na() %>% not()
models_boot_predictions[[i]] %>% colSums() %>% is.na() %>% not() %>% sum()
models_boot_predictions[[1]] %>% colSums() %>% is.na() %>% not() %>% sum()
if (is.list(models_boot_bestscores[[i]])) {
n_bestscores <- length(length(models_boot_bestscores[[i]]))
} else {
n_bestscores <- nrow(models_boot_bestscores[[i]])
}
n_bestscores
if (is.list(models_boot_bestscores[[i]])) {
n_bestscores <- length(models_boot_bestscores[[i]])
} else {
n_bestscores <- nrow(models_boot_bestscores[[i]])
}
n_bestscores
n_predictions <- models_boot_predictions[[i]] %>%
colSums() %>%
is.na() %>%
not() %>%
sum()
n_predictions
min(n_models_exist, n_bestscores, n_predictions)
start_boot <- min(n_models_exist, n_bestscores, n_predictions) + 1
start_boot
file.exists(bestscores_filename)
bestscores_filename %>% readRDS()
file.exists(boot_predictions_filename)
boot_predictions_filename %>% readRDS()
