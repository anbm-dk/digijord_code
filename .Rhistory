}
models_predictions[holdout_indices, i] <- predict_passna(
models[[i]],
holdout_i,
n_const = n_const_i
)
saveRDS(
models[[i]],
paste0(dir_results, "/model_", frac, ".rds")
)
}
# 1: Start up
# library(Cubist)
library(terra)
library(magrittr)
library(tools)
library(dplyr)
library(caret)
library(tibble)
library(tidyr)
library(xgboost)
library(doParallel)
library(spatstat) # weights
dir_code <- getwd()
root <- dirname(dir_code)
dir_dat <- paste0(root, "/digijord_data/")
source("f_predict_passna.R")
# To do:
# Pdp with depth
# Profile examples
# Test 1 - 8: Cubist
# Test 8: New covariates (chelsa, river valley bottoms, hillyness)
# Test 9: xgboost
# Test 10: Predicted row and column (poor accuracy)
# Test 11: Fever data, more
# Test 12: Depth boundaries as covariates, stepwise xgb optimization
# Test 13: Bayesian optimization
testn <- 13
mycrs <- "EPSG:25832"
# Results folder
dir_results <- dir_dat %>%
paste0(., "/results_test_", testn, "/") %T>%
dir.create()
# 2: Load observations
dir_obs_proc <- dir_dat %>%
paste0(., "/observations/processed/")
dsc <- dir_obs_proc %>%
paste0(., "dsc.csv") %>%
read.table(
header = TRUE,
sep = ";",
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
SEGES <- dir_obs_proc %>%
paste0(., "SEGES.csv") %>%
read.table(
header = TRUE,
sep = ";",
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
SINKS <- dir_obs_proc %>%
paste0(., "SINKS.csv") %>%
read.table(
header = TRUE,
sep = ";",
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
profiles_texture <- dir_obs_proc %>%
paste0(., "profiles_texture.csv") %>%
read.table(
header = TRUE,
sep = ";",
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
forest_samples <- dir_obs_proc %>%
paste0(., "forest_samples.csv") %>%
read.table(
header = TRUE,
sep = ";",
) %>%
vect(
geom = c("UTMX", "UTMY"),
crs = mycrs,
keepgeom = TRUE
)
# 3: Load folds
dir_folds <- dir_dat %>%
paste0(., "/folds/")
dsc_folds <- dir_folds %>%
paste0(., "dsc_folds.csv") %>%
read.table(
header = TRUE,
sep = ";",
)
SEGES_folds <- dir_folds %>%
paste0(., "SEGES_folds.csv") %>%
read.table(
header = TRUE,
sep = ";",
)
SINKS_folds <- dir_folds %>%
paste0(., "SINKS_folds.csv") %>%
read.table(
header = TRUE,
sep = ";",
)
profiles_folds <- dir_folds %>%
paste0(., "profiles_folds.csv") %>%
read.table(
header = TRUE,
sep = ";",
) %>%
right_join(values(profiles_texture)) %>%
select(lyr.1)
forest_folds <- dir_folds %>%
paste0(., "forest_folds.csv") %>%
read.table(
header = TRUE,
sep = ";",
)
# 4: Load covariate data
dir_cov <- dir_dat %>% paste0(., "/covariates")
cov_cats <- dir_code %>%
paste0(., "/cov_categories_20230712.csv") %>%
read.table(
sep = ";",
header = TRUE
)
cov_files <- dir_cov %>% list.files()
cov_names <- cov_files %>% tools::file_path_sans_ext()
cov_names %>%
write.table(
paste0("cov_names_", Sys.Date(), ".csv")
)
cov_names[!cov_names %in% cov_cats$name]
# 5: Load extracted covariates
dir_extr <- dir_dat %>%
paste0(., "/extracts/")
usebuffer <- FALSE
if (usebuffer) {
dsc_extr <- dir_extr %>%
paste0(., "/buffer_dsc_extr.csv") %>%
read.table(
header = TRUE,
sep = ";",
)
SEGES_extr <- dir_extr %>%
paste0(., "/buffer_SEGES_extr.csv") %>%
read.table(
header = TRUE,
sep = ";",
)
} else {
dsc_extr <- dir_extr %>%
paste0(., "/dsc_extr.rds") %>%
readRDS()
SEGES_extr <- dir_extr %>%
paste0(., "/SEGES_extr.rds") %>%
readRDS()
}
SINKS_extr <- dir_extr %>%
paste0(., "/SINKS_extr.rds") %>%
readRDS()
profiles_extr <- dir_extr %>%
paste0(., "profiles_extr.rds") %>%
readRDS() %>%
right_join(values(profiles_texture)) %>%
select(any_of(cov_names))
SINKS_extr <- dir_extr %>%
paste0(., "/SINKS_extr.rds") %>%
readRDS()
forests_extr <- dir_extr %>%
paste0(., "/forests_extr.rds") %>%
readRDS()
# 6: Merge data and transform the target variables
obs_data <- list(dsc, SEGES, SINKS, profiles_texture, forest_samples) %>%
vect() %>%
values() %>%
mutate(
logSOC = log(SOC),
logCaCO3 = log(CaCO3),
year = date %>%
as.character() %>%
substr(start = 1, stop = 4) %>%
as.numeric()
)
fractions <- c("clay", "silt", "fine_sand", "coarse_sand", "logSOC", "logCaCO3")
fractions_alt <- c("clay", "silt", "fine_sand", "coarse_sand", "SOC", "CaCO3")
fractions <- fractions_alt
fraction_names <- c(
"Clay", "Silt", "Fine sand", "Coarse sand", "SOC", "CaCO3"
)
bounds_lower <- rep(0, 6)
bounds_upper <- rep(100, 6)
# 7: Make training data
folds <- bind_rows(
dsc_folds,
SEGES_folds,
SINKS_folds,
profiles_folds,
forest_folds
)
names(folds) <- "fold"
extr <- bind_rows(
dsc_extr,
SEGES_extr,
SINKS_extr,
profiles_extr,
forests_extr
)
obs <- cbind(obs_data, extr, folds) %>%
filter(!is.na(UTMX) & !is.na(UTMY))
obs %<>%
rownames_to_column() %>%
mutate(ID_new = rowname, .before = everything()) %>%
select(-rowname)
obs_top <- obs %>%
filter(
upper < 25,
is.finite(fold)
)
obs_prf <- obs %>%
filter(
db == "Profile database",
is.finite(fold)
)
# Make new ID
obs_top_v <- obs_top %>% vect(geom = c("UTMX", "UTMY"))
library(viridisLite)
tiff(
paste0(dir_results, "/obs_map_test", testn, ".tiff"),
width = 15,
height = 10,
units = "cm",
res = 300
)
plot(
obs_top_v, "clay",
breaks = 5, breakby = "cases", col = cividis(5),
cex = 0.2
)
try(dev.off())
try(dev.off())
plot(
obs_top_v, "clay",
breaks = 5, breakby = "cases", col = cividis(5),
cex = 0.4
)
# 8: Set up models
cov_selected <- cov_cats %>%
filter(anbm_use == 1) %>%
dplyr::select(., name) %>%
unlist() %>%
unname()
# Template for custom eval
# evalerror <- function(preds, dtrain) {
#   labels <- getinfo(dtrain, "label")
#   err <- as.numeric(sum(labels != (preds > 0)))/length(labels)
#   return(list(metric = "error", value = err))
# }
# Weighted RMSE
get_RMSEw <- function(d, w) {
sqe <- w * (d[, 1] - d[, 2])^2
msqe <- sum(sqe) / sum(w)
out <- sqrt(msqe)
return(out)
}
# Weighted R^2
get_R2w <- function(d, w) {
require(boot)
out <- boot::corr(d[, 1:2], w)^2
return(out)
}
# Weighted summary function
WeightedSummary <- function(
data,
lev = NULL,
model = NULL,
...) {
out <- numeric()
out[1] <- get_RMSEw(data[, 1:2], data$weights)
out[2] <- get_R2w(data[, 1:2], data$weights)
names(out) <- c("RMSEw", "R2w")
return(out)
}
# Weighted summary function with log transformation
WeightedSummary_log <- function(
data,
lev = NULL,
model = NULL,
...) {
out <- numeric()
data[, 1:2] <- log(data[, 1:2])
data <- data[is.finite(rowSums(data)), ]
out[1] <- get_RMSEw(data[, 1:2], data$weights)
out[2] <- get_R2w(data[, 1:2], data$weights)
names(out) <- c("RMSEw_log", "R2w_log")
return(out)
}
# Weighted summary function with square root transformation
WeightedSummary_sqrt <- function(
data,
lev = NULL,
model = NULL,
...) {
out <- numeric()
data[, 1:2] <- sqrt(data[, 1:2])
data <- data[is.finite(rowSums(data)), ]
out[1] <- get_RMSEw(data[, 1:2], data$weights)
out[2] <- get_R2w(data[, 1:2], data$weights)
names(out) <- c("RMSEw_sqrt", "R2w_sqrt")
return(out)
}
metrics <- rep("RMSEw", length(fractions))
metrics[fractions == "SOC"] <- "RMSEw_log"
metrics[fractions == "CaCO3"] <- "RMSEw_sqrt"
# Function to calculate point densities
qnorm(seq(0.55, 0.95, 0.1), 0, 1)
get_dens <- function(datxy, sig) {
dens_out <- ppp(
datxy$UTMX,
datxy$UTMY,
c(441000, 894000),
c(6049000, 6403000)
) %>%
density(
sigma = sig,
at = "points",
leaveoneout = FALSE
)
attributes(dens_out) <- NULL
return(dens_out)
}
# Tuning grid
tgrid <- expand.grid(
nrounds = 10,
eta = 0.3,
max_depth = 6,
min_child_weight = 1,
gamma = 0,
colsample_bytree = 0.75,
subsample = 0.75
)
eta_test <- seq(0.1, 1, 0.1)
max_depth_test <- seq(1, 30, 3)
min_child_weight_test <- c(1, 2, 4, 8, 16, 32, 64)
gamma_test <- seq(0, 0.6, 0.1)
colsample_bytree_test <- seq(0.1, 1, 0.1)
subsample_test <- seq(0.1, 1, 0.1)
objectives <- c(rep("reg:squarederror", 4), rep("reg:tweedie", 2))
trees_per_round <- 10
# Identify OGCs and make a list with the numbers of OGCs to be tested in the
# models
ogcs_names <- extr %>%
names() %>%
grep('ogc_pi', ., value = TRUE)
ogcs_names_list <- list(ogcs_names)
n_ogcs_v <- numeric()
m <- 1
n_ogcs <- length(ogcs_names_list[[m]])
n_ogcs_v[m] <- n_ogcs
while (n_ogcs > 2) {
m <- m + 1
ogcs_names_list[[m]] <- ogcs_names_list[[m - 1]][c(TRUE, FALSE)]
n_ogcs <- length(ogcs_names_list[[m]])
n_ogcs_v[m] <- n_ogcs
}
ogcs_names_list[[length(ogcs_names_list) + 1]] <- character()
n_ogcs_v %<>% c(., 0)
# Bayesian optimization
library(ParBayesianOptimization)
bounds <- list(
eta = c(0.1, 1),
max_depth = c(1L, 50L),
min_child_weight_sqrt = c(1, sqrt(64)),
gamma_sqrt = c(0, sqrt(30)),
colsample_bytree = c(0.1, 1),
subsample = c(0.1, 1),
colsample_bylevel = c(0.1, 1),
ogcs_index = c(1L, 7L),
total_imp = c(0.5, 1)
)
scoringFunction <- function(
eta,  # OK
max_depth,  # OK
min_child_weight_sqrt,  # OK
gamma_sqrt,  # OK
colsample_bytree,  # OK
subsample,  # OK
colsample_bylevel,
ogcs_index,  # OK
total_imp  # OK
) {
# Drop unimportant covariates
cov_i_filtered <- cov_i_ranked %>%
filter(cumul < total_imp) %>%  #!
.$rowname
# Make sure SOM removal is a covariate
if ((i %in% 1:4) & !("SOM_removed" %in% cov_i_filtered)) {
cov_i_filtered %<>% c(., "SOM_removed")
}
# Add OGCs
cov_i_filtered %<>% c(., ogcs_names_list[[ogcs_index]])  # !
# Make formula
cov_formula <- cov_i_filtered %>% paste0(collapse = " + ")
formula_i <- paste0(frac, " ~ ", cov_formula) %>%
as.formula()
my_gamma <- gamma_sqrt^2
my_min_child_weight <- min_child_weight_sqrt^2
showConnections()
set.seed(1)
model_out <- caret::train(
form = formula_i,
data = trdat,
method = "xgbTree",
na.action = na.pass,
tuneGrid = expand.grid(
nrounds = tgrid$nrounds,
eta = eta,  # !
max_depth = max_depth,  # !
min_child_weight = my_min_child_weight, # !
gamma = my_gamma, # !
colsample_bytree = colsample_bytree, # !
subsample = subsample # !
),
trControl = trainControl(
index = folds_i,
savePredictions = "final",
predictionBounds = c(bounds_lower_i, bounds_upper_i),
summaryFunction = sumfun,
allowParallel = FALSE
),
metric = metrics_i,
maximize = FALSE,
weights = trdat$w,
num_parallel_tree = trees_per_round,
objective = objectives_i,
colsample_bylevel = colsample_bylevel,
nthread = 1
)
min_RMSEw <- model_out$results %>%
select(any_of(metrics_i)) %>%
min()
return(
list(
Score = 0 - min_RMSEw,
n_ogcs = length(ogcs_names_list[[ogcs_index]]),
gamma = my_gamma,
min_child_weight = my_min_child_weight,
n_cov = length(cov_i_filtered)
)
)
}
xgb_opt_stepwise <- FALSE
# Small random sample for testing
# Remember to include full dataset in the final model
n <- 1000
use_all_points <- TRUE
# use_all_points <- FALSE
extra_tuning_xgb <- TRUE
# extra_tuning_xgb <- FALSE
# 9: Train models
n_ogcs_models <- numeric()
total_imp_models <- numeric()
weights_objects <- list()
models_tr_summaries <- list()
models_scoreresults <- list()
models_bestscores <- list()
# Covariate selection:
# Step 1: Decide the optimal number of OGCs
# Step 2: Drop unimportant covariates
# xgb optimization:
# Step 1: Adjust learning rate
# Step 2: Fit max_depth and min_child_weight
# Step 3: Tune gamma
# Step 4: Adjust subsampling
# Step 5: Increase nrounds, readjust learning rate
# Test OGC after model tuning?
models_predictions <- matrix(
numeric(),
nrow = nrow(obs),
ncol = length(fractions)
)
models_weights <- matrix(
numeric(),
nrow = nrow(obs),
ncol = length(fractions)
)
models_indices <- matrix(
numeric(),
nrow = nrow(obs),
ncol = length(fractions)
)
colnames(models_predictions) <- fractions
colnames(models_weights) <- fractions
models <- list()
